[2021-12-29 11:56:57,416] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: scraping_daft_dublin.scrap_data scheduled__2021-12-28T09:30:00+00:00 [queued]>
[2021-12-29 11:56:58,383] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: scraping_daft_dublin.scrap_data scheduled__2021-12-28T09:30:00+00:00 [queued]>
[2021-12-29 11:56:58,409] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2021-12-29 11:56:58,438] {taskinstance.py:1242} INFO - Starting attempt 1 of 4
[2021-12-29 11:56:58,451] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2021-12-29 11:57:01,611] {taskinstance.py:1262} INFO - Executing <Task(SparkSubmitOperator): scrap_data> on 2021-12-28 09:30:00+00:00
[2021-12-29 11:57:06,052] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'scraping_daft_dublin', 'scrap_data', 'scheduled__2021-12-28T09:30:00+00:00', '--job-id', '5320', '--raw', '--subdir', 'DAGS_FOLDER/scraping_daft_dublin.py', '--cfg-path', '/tmp/tmpaxpe8oi2', '--error-file', '/tmp/tmpr0f8nuld']
[2021-12-29 11:57:06,099] {standard_task_runner.py:77} INFO - Job 5320: Subtask scrap_data
[2021-12-29 11:57:05,267] {standard_task_runner.py:52} INFO - Started process 24569 to run task
[2021-12-29 11:57:08,537] {logging_mixin.py:109} INFO - Running <TaskInstance: scraping_daft_dublin.scrap_data scheduled__2021-12-28T09:30:00+00:00 [running]> on host 6bdda4c19a85
[2021-12-29 11:57:10,394] {taskinstance.py:1429} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=clement.liscoet@gmail.com
AIRFLOW_CTX_DAG_OWNER=clemoni
AIRFLOW_CTX_DAG_ID=scraping_daft_dublin
AIRFLOW_CTX_TASK_ID=scrap_data
AIRFLOW_CTX_EXECUTION_DATE=2021-12-28T09:30:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-28T09:30:00+00:00
[2021-12-29 11:57:10,859] {base.py:79} INFO - Using connection to: id: spark_default. Host: spark://spark:7077, Port: None, Schema: , Login: ***, Password: ***, extra: {}
[2021-12-29 11:57:10,982] {spark_submit.py:360} INFO - Spark-Submit cmd: spark-submit --master spark://spark:7077 --conf spark.master=spark://spark:7077 --name scrap data --verbose /opt/***/jobs/get_ads_per_county.py dublin
[2021-12-29 11:58:42,195] {spark_submit.py:514} INFO - Using properties file: null
[2021-12-29 11:59:09,616] {spark_submit.py:514} INFO - WARNING: An illegal reflective access operation has occurred
[2021-12-29 11:59:09,648] {spark_submit.py:514} INFO - WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/***/.local/lib/python3.6/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
[2021-12-29 11:59:09,652] {spark_submit.py:514} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
[2021-12-29 11:59:09,655] {spark_submit.py:514} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2021-12-29 11:59:09,661] {spark_submit.py:514} INFO - WARNING: All illegal access operations will be denied in a future release
[2021-12-29 11:59:21,984] {spark_submit.py:514} INFO - Parsed arguments:
[2021-12-29 11:59:22,066] {spark_submit.py:514} INFO - master                  spark://spark:7077
[2021-12-29 11:59:22,069] {spark_submit.py:514} INFO - deployMode              null
[2021-12-29 11:59:22,071] {spark_submit.py:514} INFO - executorMemory          null
[2021-12-29 11:59:22,073] {spark_submit.py:514} INFO - executorCores           null
[2021-12-29 11:59:22,075] {spark_submit.py:514} INFO - totalExecutorCores      null
[2021-12-29 11:59:22,077] {spark_submit.py:514} INFO - propertiesFile          null
[2021-12-29 11:59:22,082] {spark_submit.py:514} INFO - driverMemory            null
[2021-12-29 11:59:22,089] {spark_submit.py:514} INFO - driverCores             null
[2021-12-29 11:59:22,092] {spark_submit.py:514} INFO - driverExtraClassPath    null
[2021-12-29 11:59:22,096] {spark_submit.py:514} INFO - driverExtraLibraryPath  null
[2021-12-29 11:59:22,100] {spark_submit.py:514} INFO - driverExtraJavaOptions  null
[2021-12-29 11:59:22,102] {spark_submit.py:514} INFO - supervise               false
[2021-12-29 11:59:22,105] {spark_submit.py:514} INFO - queue                   null
[2021-12-29 11:59:22,111] {spark_submit.py:514} INFO - numExecutors            null
[2021-12-29 11:59:22,117] {spark_submit.py:514} INFO - files                   null
[2021-12-29 11:59:22,122] {spark_submit.py:514} INFO - pyFiles                 null
[2021-12-29 11:59:22,125] {spark_submit.py:514} INFO - archives                null
[2021-12-29 11:59:22,129] {spark_submit.py:514} INFO - mainClass               null
[2021-12-29 11:59:22,130] {spark_submit.py:514} INFO - primaryResource         file:/opt/***/jobs/get_ads_per_county.py
[2021-12-29 11:59:22,136] {spark_submit.py:514} INFO - name                    scrap data
[2021-12-29 11:59:22,146] {spark_submit.py:514} INFO - childArgs               [dublin]
[2021-12-29 11:59:22,148] {spark_submit.py:514} INFO - jars                    null
[2021-12-29 11:59:22,151] {spark_submit.py:514} INFO - packages                null
[2021-12-29 11:59:22,154] {spark_submit.py:514} INFO - packagesExclusions      null
[2021-12-29 11:59:22,158] {spark_submit.py:514} INFO - repositories            null
[2021-12-29 11:59:22,165] {spark_submit.py:514} INFO - verbose                 true
[2021-12-29 11:59:22,169] {spark_submit.py:514} INFO - 
[2021-12-29 11:59:22,171] {spark_submit.py:514} INFO - Spark properties used, including those specified through
[2021-12-29 11:59:22,174] {spark_submit.py:514} INFO - --conf and those from the properties file null:
[2021-12-29 11:59:22,177] {spark_submit.py:514} INFO - (spark.master,spark://spark:7077)
[2021-12-29 11:59:22,181] {spark_submit.py:514} INFO - 
[2021-12-29 11:59:22,186] {spark_submit.py:514} INFO - 
[2021-12-29 11:59:53,820] {spark_submit.py:514} INFO - Main class:
[2021-12-29 11:59:53,828] {spark_submit.py:514} INFO - org.apache.spark.deploy.PythonRunner
[2021-12-29 11:59:53,832] {spark_submit.py:514} INFO - Arguments:
[2021-12-29 11:59:53,840] {spark_submit.py:514} INFO - file:/opt/***/jobs/get_ads_per_county.py
[2021-12-29 11:59:53,848] {spark_submit.py:514} INFO - null
[2021-12-29 11:59:53,854] {spark_submit.py:514} INFO - dublin
[2021-12-29 11:59:53,858] {spark_submit.py:514} INFO - --verbose
[2021-12-29 11:59:53,996] {spark_submit.py:514} INFO - Spark config:
[2021-12-29 11:59:53,999] {spark_submit.py:514} INFO - (spark.app.name,scrap data)
[2021-12-29 11:59:54,002] {spark_submit.py:514} INFO - (spark.master,spark://spark:7077)
[2021-12-29 11:59:54,004] {spark_submit.py:514} INFO - (spark.submit.pyFiles,)
[2021-12-29 11:59:54,007] {spark_submit.py:514} INFO - (spark.submit.deployMode,client)
[2021-12-29 11:59:54,009] {spark_submit.py:514} INFO - Classpath elements:
[2021-12-29 11:59:54,012] {spark_submit.py:514} INFO - 
[2021-12-29 11:59:54,015] {spark_submit.py:514} INFO - 
[2021-12-29 11:59:54,017] {spark_submit.py:514} INFO - 
[2021-12-29 12:00:11,438] {spark_submit.py:514} INFO - Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
[2021-12-29 12:00:11,695] {spark_submit.py:514} INFO - 21/12/29 12:00:11 INFO SparkContext: Running Spark version 3.2.0
[2021-12-29 12:00:14,493] {spark_submit.py:514} INFO - 21/12/29 12:00:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2021-12-29 12:00:17,416] {spark_submit.py:514} INFO - 21/12/29 12:00:17 INFO ResourceUtils: ==============================================================
[2021-12-29 12:00:17,455] {spark_submit.py:514} INFO - 21/12/29 12:00:17 INFO ResourceUtils: No custom resources configured for spark.driver.
[2021-12-29 12:00:17,460] {spark_submit.py:514} INFO - 21/12/29 12:00:17 INFO ResourceUtils: ==============================================================
[2021-12-29 12:00:17,463] {spark_submit.py:514} INFO - 21/12/29 12:00:17 INFO SparkContext: Submitted application: Get Ads per county
[2021-12-29 12:00:17,797] {spark_submit.py:514} INFO - 21/12/29 12:00:17 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2021-12-29 12:00:18,157] {spark_submit.py:514} INFO - 21/12/29 12:00:18 INFO ResourceProfile: Limiting resource is cpu
[2021-12-29 12:00:18,173] {spark_submit.py:514} INFO - 21/12/29 12:00:18 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2021-12-29 12:00:19,522] {spark_submit.py:514} INFO - 21/12/29 12:00:19 INFO SecurityManager: Changing view acls to: ***
[2021-12-29 12:00:19,527] {spark_submit.py:514} INFO - 21/12/29 12:00:19 INFO SecurityManager: Changing modify acls to: ***
[2021-12-29 12:00:19,539] {spark_submit.py:514} INFO - 21/12/29 12:00:19 INFO SecurityManager: Changing view acls groups to:
[2021-12-29 12:00:19,546] {spark_submit.py:514} INFO - 21/12/29 12:00:19 INFO SecurityManager: Changing modify acls groups to:
[2021-12-29 12:00:19,565] {spark_submit.py:514} INFO - 21/12/29 12:00:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(***); groups with view permissions: Set(); users  with modify permissions: Set(***); groups with modify permissions: Set()
[2021-12-29 12:00:24,348] {spark_submit.py:514} INFO - 21/12/29 12:00:24 INFO Utils: Successfully started service 'sparkDriver' on port 35967.
[2021-12-29 12:00:25,337] {spark_submit.py:514} INFO - 21/12/29 12:00:25 INFO SparkEnv: Registering MapOutputTracker
[2021-12-29 12:00:26,858] {spark_submit.py:514} INFO - 21/12/29 12:00:26 INFO SparkEnv: Registering BlockManagerMaster
[2021-12-29 12:00:27,709] {spark_submit.py:514} INFO - 21/12/29 12:00:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2021-12-29 12:00:27,719] {spark_submit.py:514} INFO - 21/12/29 12:00:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2021-12-29 12:00:27,854] {spark_submit.py:514} INFO - 21/12/29 12:00:27 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2021-12-29 12:00:28,966] {spark_submit.py:514} INFO - 21/12/29 12:00:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a3f43a1d-338d-4a1c-98e6-c1bc8e7fe7c2
[2021-12-29 12:00:29,384] {spark_submit.py:514} INFO - 21/12/29 12:00:29 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2021-12-29 12:00:29,585] {spark_submit.py:514} INFO - 21/12/29 12:00:29 INFO SparkEnv: Registering OutputCommitCoordinator
[2021-12-29 12:00:33,385] {spark_submit.py:514} INFO - 21/12/29 12:00:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2021-12-29 12:00:33,387] {spark_submit.py:514} INFO - 21/12/29 12:00:33 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[2021-12-29 12:00:33,388] {spark_submit.py:514} INFO - 21/12/29 12:00:33 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[2021-12-29 12:00:33,605] {spark_submit.py:514} INFO - 21/12/29 12:00:33 INFO Utils: Successfully started service 'SparkUI' on port 4043.
[2021-12-29 12:00:34,400] {spark_submit.py:514} INFO - 21/12/29 12:00:34 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://6bdda4c19a85:4043
[2021-12-29 12:00:37,679] {spark_submit.py:514} INFO - 21/12/29 12:00:37 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark:7077...
[2021-12-29 12:00:40,567] {spark_submit.py:514} INFO - 21/12/29 12:00:40 INFO TransportClientFactory: Successfully created connection to spark/172.18.0.4:7077 after 2077 ms (0 ms spent in bootstraps)
[2021-12-29 12:00:42,884] {spark_submit.py:514} INFO - 21/12/29 12:00:42 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211229120042-0075
[2021-12-29 12:00:43,550] {spark_submit.py:514} INFO - 21/12/29 12:00:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41925.
[2021-12-29 12:00:43,663] {spark_submit.py:514} INFO - 21/12/29 12:00:43 INFO NettyBlockTransferService: Server created on 6bdda4c19a85:41925
[2021-12-29 12:00:43,915] {spark_submit.py:514} INFO - 21/12/29 12:00:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2021-12-29 12:00:44,806] {spark_submit.py:514} INFO - 21/12/29 12:00:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6bdda4c19a85, 41925, None)
[2021-12-29 12:00:44,905] {spark_submit.py:514} INFO - 21/12/29 12:00:44 INFO BlockManagerMasterEndpoint: Registering block manager 6bdda4c19a85:41925 with 434.4 MiB RAM, BlockManagerId(driver, 6bdda4c19a85, 41925, None)
[2021-12-29 12:00:45,179] {spark_submit.py:514} INFO - 21/12/29 12:00:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6bdda4c19a85, 41925, None)
[2021-12-29 12:00:45,262] {spark_submit.py:514} INFO - 21/12/29 12:00:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6bdda4c19a85, 41925, None)
[2021-12-29 12:01:11,239] {spark_submit.py:514} INFO - 21/12/29 12:01:10 WARN StandaloneAppClient$ClientEndpoint: Connection to 6e865cc8a9f9:7077 failed; waiting for master to reconnect...
[2021-12-29 12:01:11,296] {spark_submit.py:514} INFO - 21/12/29 12:01:11 WARN StandaloneSchedulerBackend: Disconnected from Spark cluster! Waiting for reconnection...
[2021-12-29 12:01:12,551] {spark_submit.py:514} INFO - 21/12/29 12:01:12 INFO AsyncEventQueue: Process of event SparkListenerResourceProfileAdded(Profile: id = 0, executor resources: cores -> name: cores, amount: 1, script: , vendor: ,memory -> name: memory, amount: 1024, script: , vendor: ,offHeap -> name: offHeap, amount: 0, script: , vendor: , task resources: cpus -> name: cpus, amount: 1.0) by listener HeartbeatReceiver took 4.9200807s.
[2021-12-29 12:01:12,661] {spark_submit.py:514} INFO - 21/12/29 12:01:12 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2021-12-29 12:01:12,994] {spark_submit.py:514} INFO - 21/12/29 12:01:12 INFO AsyncEventQueue: Process of event SparkListenerResourceProfileAdded(Profile: id = 0, executor resources: cores -> name: cores, amount: 1, script: , vendor: ,memory -> name: memory, amount: 1024, script: , vendor: ,offHeap -> name: offHeap, amount: 0, script: , vendor: , task resources: cpus -> name: cpus, amount: 1.0) by listener AppStatusListener took 6.9687223s.
[2021-12-29 12:01:14,522] {spark_submit.py:514} INFO - /home/***/.local/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.
[2021-12-29 12:01:14,535] {spark_submit.py:514} INFO - FutureWarning
[2021-12-29 12:01:51,029] {spark_submit.py:514} INFO - 21/12/29 12:01:50 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2021-12-29 12:02:14,205] {spark_submit.py:514} INFO - 21/12/29 12:02:14 INFO SharedState: Warehouse path is 'file:/opt/***/spark-warehouse'.
[2021-12-29 12:02:51,212] {spark_submit.py:514} INFO - running...
[2021-12-29 12:02:53,517] {spark_submit.py:514} INFO - running...
[2021-12-29 12:03:00,927] {spark_submit.py:514} INFO - running...
[2021-12-29 12:03:06,465] {spark_submit.py:514} INFO - running...
[2021-12-29 12:03:10,144] {spark_submit.py:514} INFO - running...
[2021-12-29 12:03:15,694] {spark_submit.py:514} INFO - running...
[2021-12-29 12:03:20,734] {spark_submit.py:514} INFO - running...
[2021-12-29 12:03:26,350] {spark_submit.py:514} INFO - running...
[2021-12-29 12:03:30,380] {spark_submit.py:514} INFO - running...
[2021-12-29 12:03:33,680] {spark_submit.py:514} INFO - running...
[2021-12-29 12:03:38,654] {spark_submit.py:514} INFO - running...
[2021-12-29 12:03:39,733] {spark_submit.py:514} INFO - running...
[2021-12-29 12:03:43,111] {spark_submit.py:514} INFO - running...
[2021-12-29 12:03:47,245] {spark_submit.py:514} INFO - running...
[2021-12-29 12:03:54,721] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:00,699] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:03,078] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:04,875] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:06,314] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:11,188] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:18,226] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:19,988] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:22,326] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:25,715] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:26,479] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:26,481] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:29,209] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:30,123] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:32,699] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:34,894] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:36,332] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:39,586] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:42,589] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:43,957] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:44,720] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:45,346] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:46,754] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:47,877] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:48,808] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:53,710] {spark_submit.py:514} INFO - running...
[2021-12-29 12:04:58,710] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:03,596] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:06,434] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:07,442] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:08,186] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:09,135] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:09,876] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:11,039] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:11,598] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:13,280] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:14,379] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:15,473] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:17,306] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:18,050] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:18,936] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:19,678] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:20,458] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:21,199] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:21,780] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:23,248] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:25,370] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:27,202] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:27,701] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:29,617] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:31,154] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:32,347] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:34,447] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:37,052] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:37,623] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:38,109] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:38,896] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:39,636] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:40,385] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:41,044] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:42,063] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:42,609] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:43,464] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:44,462] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:45,549] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:46,100] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:49,072] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:49,592] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:50,278] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:50,982] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:51,546] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:52,069] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:52,522] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:53,299] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:53,859] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:54,801] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:55,464] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:56,141] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:57,036] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:58,024] {spark_submit.py:514} INFO - running...
[2021-12-29 12:05:59,276] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:00,448] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:01,694] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:02,754] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:03,874] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:05,006] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:09,182] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:10,610] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:11,870] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:13,507] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:14,879] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:16,530] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:17,807] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:19,283] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:20,498] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:21,357] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:22,238] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:23,069] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:23,637] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:24,303] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:25,010] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:25,639] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:26,224] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:26,778] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:27,703] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:28,609] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:30,088] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:30,667] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:32,126] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:33,824] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:34,433] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:35,463] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:36,158] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:36,833] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:37,476] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:37,965] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:38,544] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:39,534] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:40,188] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:41,062] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:41,493] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:42,068] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:43,081] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:43,710] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:44,522] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:45,283] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:46,552] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:47,584] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:48,414] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:48,878] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:49,415] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:49,919] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:50,402] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:51,132] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:51,863] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:52,450] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:53,242] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:53,985] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:54,791] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:55,600] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:56,242] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:57,030] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:57,817] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:58,711] {spark_submit.py:514} INFO - running...
[2021-12-29 12:06:59,480] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:00,090] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:01,473] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:02,024] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:02,849] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:03,648] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:04,921] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:06,290] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:07,800] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:08,451] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:09,115] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:09,983] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:10,654] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:11,205] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:11,948] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:12,334] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:12,749] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:13,317] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:13,931] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:14,498] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:15,210] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:15,887] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:18,413] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:19,653] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:20,477] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:21,469] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:21,916] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:22,501] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:23,083] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:23,863] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:24,737] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:25,428] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:26,273] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:26,802] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:27,440] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:28,291] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:29,203] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:29,767] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:30,673] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:31,156] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:31,830] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:32,641] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:34,805] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:35,533] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:36,175] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:37,220] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:38,037] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:39,198] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:40,278] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:41,959] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:42,861] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:43,524] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:44,634] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:45,477] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:46,609] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:47,418] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:48,161] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:48,886] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:49,723] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:51,165] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:52,469] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:53,680] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:58,517] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:59,025] {spark_submit.py:514} INFO - running...
[2021-12-29 12:07:59,867] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:00,729] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:02,556] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:03,460] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:04,114] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:04,712] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:05,644] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:06,569] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:07,786] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:08,803] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:10,067] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:11,073] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:12,365] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:13,425] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:14,261] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:15,347] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:16,040] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:17,533] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:19,391] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:20,190] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:20,782] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:21,263] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:21,999] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:22,624] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:23,238] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:24,033] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:24,840] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:25,519] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:26,264] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:28,049] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:28,799] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:30,143] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:31,782] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:33,503] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:34,154] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:34,877] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:35,740] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:36,465] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:38,426] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:39,312] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:39,984] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:40,688] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:41,451] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:41,954] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:42,521] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:43,367] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:44,951] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:46,386] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:47,384] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:48,198] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:48,846] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:49,403] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:51,160] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:53,030] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:53,666] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:55,461] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:55,940] {spark_submit.py:514} INFO - running...
[2021-12-29 12:08:56,605] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:00,743] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:01,495] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:02,196] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:03,080] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:03,908] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:04,505] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:05,240] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:06,830] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:07,829] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:09,704] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:11,602] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:12,439] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:13,131] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:15,161] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:15,740] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:16,432] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:17,048] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:19,534] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:20,765] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:21,531] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:24,058] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:25,647] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:26,627] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:27,682] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:28,449] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:29,034] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:29,800] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:30,373] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:30,925] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:31,530] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:32,451] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:33,541] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:34,205] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:34,748] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:35,456] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:36,489] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:37,311] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:38,166] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:39,132] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:40,175] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:43,169] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:43,889] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:44,715] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:45,668] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:46,317] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:46,989] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:47,990] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:49,061] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:49,804] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:50,494] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:51,595] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:53,082] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:54,304] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:55,350] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:56,079] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:56,826] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:57,380] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:58,265] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:59,114] {spark_submit.py:514} INFO - running...
[2021-12-29 12:09:59,987] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:02,031] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:02,692] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:03,833] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:04,595] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:05,660] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:12,838] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:14,397] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:16,414] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:17,668] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:18,666] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:19,956] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:21,606] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:23,017] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:24,443] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:25,243] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:26,866] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:28,726] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:30,437] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:31,534] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:32,978] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:36,456] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:37,552] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:38,491] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:39,376] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:40,166] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:40,901] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:41,822] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:42,614] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:43,488] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:44,300] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:44,983] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:45,617] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:46,283] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:47,111] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:48,053] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:49,126] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:49,709] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:50,733] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:51,416] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:52,074] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:54,261] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:55,077] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:55,697] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:56,451] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:57,021] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:57,667] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:58,374] {spark_submit.py:514} INFO - running...
[2021-12-29 12:10:59,347] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:00,776] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:02,318] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:03,267] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:04,008] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:04,763] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:05,764] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:06,488] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:07,156] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:07,978] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:08,616] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:09,405] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:09,998] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:12,013] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:13,010] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:14,596] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:15,763] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:16,853] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:18,345] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:18,991] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:19,733] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:20,529] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:20,941] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:21,577] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:22,373] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:23,112] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:24,037] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:24,930] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:25,573] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:26,426] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:26,901] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:27,893] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:28,614] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:30,699] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:31,784] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:32,493] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:33,082] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:33,973] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:34,665] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:36,080] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:37,504] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:38,356] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:39,351] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:40,524] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:42,214] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:43,773] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:44,440] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:45,099] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:46,546] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:47,412] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:48,185] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:48,801] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:49,434] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:51,759] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:52,530] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:53,399] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:54,240] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:54,972] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:55,568] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:56,374] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:57,220] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:58,069] {spark_submit.py:514} INFO - running...
[2021-12-29 12:11:59,191] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:00,167] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:01,097] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:01,714] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:02,546] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:03,462] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:04,306] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:05,098] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:05,794] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:06,323] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:07,162] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:08,706] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:09,160] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:09,793] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:10,624] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:12,245] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:13,889] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:14,714] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:15,226] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:15,791] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:16,460] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:17,039] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:17,725] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:18,136] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:18,757] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:19,214] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:19,874] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:20,764] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:21,642] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:22,114] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:22,561] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:23,739] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:24,280] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:24,873] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:25,685] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:26,611] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:27,302] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:27,783] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:28,288] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:29,003] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:29,677] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:30,615] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:31,132] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:32,029] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:32,589] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:33,457] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:34,906] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:35,518] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:36,124] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:36,906] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:38,078] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:41,681] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:42,248] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:42,799] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:43,632] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:44,300] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:45,963] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:46,477] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:47,385] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:49,156] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:50,062] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:50,852] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:51,627] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:52,489] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:54,380] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:54,924] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:55,551] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:56,127] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:56,878] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:57,527] {spark_submit.py:514} INFO - running...
[2021-12-29 12:12:58,178] {spark_submit.py:514} INFO - running...
[2021-12-29 12:13:05,136] {spark_submit.py:514} INFO - running...
[2021-12-29 12:13:07,307] {spark_submit.py:514} INFO - running...
[2021-12-29 12:13:08,949] {spark_submit.py:514} INFO - running...
[2021-12-29 12:13:10,760] {spark_submit.py:514} INFO - running...
[2021-12-29 12:13:12,561] {spark_submit.py:514} INFO - running...
[2021-12-29 12:13:14,417] {spark_submit.py:514} INFO - running...
[2021-12-29 12:13:14,971] {spark_submit.py:514} INFO - running...
[2021-12-29 12:13:16,730] {spark_submit.py:514} INFO - running...
[2021-12-29 12:13:19,600] {spark_submit.py:514} INFO - IncompleteRead(68456 bytes read, 237963 more expected)
[2021-12-29 12:13:19,613] {spark_submit.py:514} INFO - Traceback (most recent call last):
[2021-12-29 12:13:19,618] {spark_submit.py:514} INFO - File "/opt/***/jobs/get_ads_per_county.py", line 17, in <module>
[2021-12-29 12:13:19,622] {spark_submit.py:514} INFO - get_rent_parse_county_json(county)
[2021-12-29 12:13:19,624] {spark_submit.py:514} INFO - File "/opt/***/jobs/my_packages/fptools/fptools.py", line 191, in h
[2021-12-29 12:13:19,627] {spark_submit.py:514} INFO - return g(x, f(x))
[2021-12-29 12:13:19,630] {spark_submit.py:514} INFO - File "/opt/***/jobs/my_packages/main.py", line 32, in run_get_ads_by_county
[2021-12-29 12:13:19,633] {spark_submit.py:514} INFO - get_daft)(limit, county=county)
[2021-12-29 12:13:19,634] {spark_submit.py:514} INFO - File "/opt/***/jobs/my_packages/scraptools/scrap_main.py", line 254, in get_adds_by_page
[2021-12-29 12:13:19,636] {spark_submit.py:514} INFO - return get_adds_by_page(limit, county=county, page=next_page, res=res)
[2021-12-29 12:13:19,637] {spark_submit.py:514} INFO - File "/opt/***/jobs/my_packages/scraptools/scrap_main.py", line 254, in get_adds_by_page
[2021-12-29 12:13:19,639] {spark_submit.py:514} INFO - return get_adds_by_page(limit, county=county, page=next_page, res=res)
[2021-12-29 12:13:19,641] {spark_submit.py:514} INFO - File "/opt/***/jobs/my_packages/scraptools/scrap_main.py", line 254, in get_adds_by_page
[2021-12-29 12:13:19,645] {spark_submit.py:514} INFO - return get_adds_by_page(limit, county=county, page=next_page, res=res)
[2021-12-29 12:13:19,646] {spark_submit.py:514} INFO - [Previous line repeated 23 more times]
[2021-12-29 12:13:19,647] {spark_submit.py:514} INFO - File "/opt/***/jobs/my_packages/scraptools/scrap_main.py", line 252, in get_adds_by_page
[2021-12-29 12:13:19,650] {spark_submit.py:514} INFO - res.append(extract_and_get_data_ads(get_daft, url, county)(daft))
[2021-12-29 12:13:19,730] {spark_submit.py:514} INFO - File "/opt/***/jobs/my_packages/scraptools/scrap_main.py", line 193, in h
[2021-12-29 12:13:19,856] {spark_submit.py:514} INFO - return g(*args)(f(x))
[2021-12-29 12:13:19,862] {spark_submit.py:514} INFO - File "/opt/***/jobs/my_packages/scraptools/scrap_main.py", line 181, in get_data_ads
[2021-12-29 12:13:19,870] {spark_submit.py:514} INFO - res.append(parse_advert_from_daft(ad))
[2021-12-29 12:13:19,879] {spark_submit.py:514} INFO - File "/opt/***/jobs/my_packages/scraptools/scrap_main.py", line 120, in parse_advert
[2021-12-29 12:13:19,883] {spark_submit.py:514} INFO - ad_data = get_ad_data(ad)
[2021-12-29 12:13:19,886] {spark_submit.py:514} INFO - File "/opt/***/jobs/my_packages/fptools/fptools.py", line 184, in format_compose
[2021-12-29 12:13:19,888] {spark_submit.py:514} INFO - vals = [f(x) for f in funcs]
[2021-12-29 12:13:19,894] {spark_submit.py:514} INFO - File "/opt/***/jobs/my_packages/fptools/fptools.py", line 184, in <listcomp>
[2021-12-29 12:13:19,898] {spark_submit.py:514} INFO - vals = [f(x) for f in funcs]
[2021-12-29 12:13:19,899] {spark_submit.py:514} INFO - File "/opt/***/jobs/my_packages/fptools/fptools.py", line 35, in h
[2021-12-29 12:13:19,902] {spark_submit.py:514} INFO - return g(f(x))
[2021-12-29 12:13:19,906] {spark_submit.py:514} INFO - File "/opt/***/jobs/my_packages/scraptools/scrap_info.py", line 37, in extract_id
[2021-12-29 12:13:19,909] {spark_submit.py:514} INFO - return ad.find('p', {'class': re.compile('DaftIDText.')}).get_text()
[2021-12-29 12:13:19,912] {spark_submit.py:514} INFO - AttributeError: 'NoneType' object has no attribute 'find'
[2021-12-29 12:13:22,475] {spark_submit.py:514} INFO - 21/12/29 12:13:22 INFO SparkContext: Invoking stop() from shutdown hook
[2021-12-29 12:13:23,895] {spark_submit.py:514} INFO - 21/12/29 12:13:23 INFO SparkUI: Stopped Spark web UI at http://6bdda4c19a85:4043
[2021-12-29 12:13:23,974] {spark_submit.py:514} INFO - 21/12/29 12:13:23 INFO StandaloneSchedulerBackend: Shutting down all executors
[2021-12-29 12:13:24,027] {spark_submit.py:514} INFO - 21/12/29 12:13:24 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
[2021-12-29 12:13:24,264] {spark_submit.py:514} INFO - 21/12/29 12:13:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2021-12-29 12:13:24,421] {spark_submit.py:514} INFO - 21/12/29 12:13:24 INFO MemoryStore: MemoryStore cleared
[2021-12-29 12:13:24,425] {spark_submit.py:514} INFO - 21/12/29 12:13:24 INFO BlockManager: BlockManager stopped
[2021-12-29 12:13:24,478] {spark_submit.py:514} INFO - 21/12/29 12:13:24 INFO BlockManagerMaster: BlockManagerMaster stopped
[2021-12-29 12:13:24,494] {spark_submit.py:514} INFO - 21/12/29 12:13:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2021-12-29 12:13:24,554] {spark_submit.py:514} INFO - 21/12/29 12:13:24 INFO SparkContext: Successfully stopped SparkContext
[2021-12-29 12:13:24,563] {spark_submit.py:514} INFO - 21/12/29 12:13:24 INFO ShutdownHookManager: Shutdown hook called
[2021-12-29 12:13:24,567] {spark_submit.py:514} INFO - 21/12/29 12:13:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-9e26378d-c50b-4a90-914d-8a84abd334a5/pyspark-e7247b06-e168-42a2-a82e-53f1e357fcd0
[2021-12-29 12:13:24,583] {spark_submit.py:514} INFO - 21/12/29 12:13:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-9e26378d-c50b-4a90-914d-8a84abd334a5
[2021-12-29 12:13:24,609] {spark_submit.py:514} INFO - 21/12/29 12:13:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-3b41a936-abaf-4e4b-a3ab-9057bbb5cce2
[2021-12-29 12:47:28,434] {local_task_job.py:142} ERROR - Heartbeat time limit exceeded!
[2021-12-29 12:47:33,172] {process_utils.py:100} INFO - Sending Signals.SIGTERM to GPID 24569
[2021-12-29 12:47:35,242] {taskinstance.py:1411} ERROR - Received SIGTERM. Terminating subprocesses.
[2021-12-29 12:47:35,543] {standard_task_runner.py:91} ERROR - Failed to execute job 5320 for task scrap_data
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1332, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1458, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1514, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 179, in execute
    self._hook.submit(self._application)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 446, in submit
    f"Cannot execute: {self._mask_cmd(spark_submit_cmd)}. Error code is: {returncode}."
airflow.exceptions.AirflowException: Cannot execute: spark-submit --master spark://spark:7077 --conf spark.master=spark://spark:7077 --name scrap data --verbose /opt/***/jobs/get_ads_per_county.py dublin. Error code is: 1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 292, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1375, in _run_raw_task
    self.refresh_from_db(lock_for_update=True, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 729, in refresh_from_db
    ti: Optional[TaskInstance] = qry.with_for_update().first()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3429, in first
    ret = list(self[0:1])
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3203, in __getitem__
    return list(res)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3560, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1514, in _handle_dbapi_exception
    util.raise_(exc_info[1], with_traceback=exc_info[2])
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
  File "/usr/local/lib/python3.6/encodings/utf_8.py", line 15, in decode
    def decode(input, errors='strict'):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1413, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2021-12-29 12:47:38,071] {process_utils.py:66} INFO - Process psutil.Process(pid=24569, status='terminated', exitcode=1, started='11:57:05') (24569) terminated with exit code 1
