[2021-12-29 09:56:04,700] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: scraping_daft_kerry.run_init_county scheduled__2021-12-28T09:40:00+00:00 [queued]>
[2021-12-29 09:56:13,193] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: scraping_daft_kerry.run_init_county scheduled__2021-12-28T09:40:00+00:00 [queued]>
[2021-12-29 09:56:13,199] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2021-12-29 09:56:13,203] {taskinstance.py:1242} INFO - Starting attempt 1 of 4
[2021-12-29 09:56:13,209] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2021-12-29 09:56:14,462] {taskinstance.py:1262} INFO - Executing <Task(_PythonDecoratedOperator): run_init_county> on 2021-12-28 09:40:00+00:00
[2021-12-29 09:56:31,981] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'scraping_daft_kerry', 'run_init_county', 'scheduled__2021-12-28T09:40:00+00:00', '--job-id', '5307', '--raw', '--subdir', 'DAGS_FOLDER/scraping_daft_kerry.py', '--cfg-path', '/tmp/tmpa38n637d', '--error-file', '/tmp/tmpru177zq7']
[2021-12-29 09:56:32,357] {standard_task_runner.py:77} INFO - Job 5307: Subtask run_init_county
[2021-12-29 09:56:31,479] {standard_task_runner.py:52} INFO - Started process 24224 to run task
[2021-12-29 09:56:38,236] {logging_mixin.py:109} INFO - Running <TaskInstance: scraping_daft_kerry.run_init_county scheduled__2021-12-28T09:40:00+00:00 [running]> on host 6bdda4c19a85
[2021-12-29 10:01:49,590] {local_task_job.py:142} ERROR - Heartbeat time limit exceeded!
[2021-12-29 10:02:13,249] {process_utils.py:100} INFO - Sending Signals.SIGTERM to GPID 24224
[2021-12-29 10:02:13,512] {taskinstance.py:1411} ERROR - Received SIGTERM. Terminating subprocesses.
[2021-12-29 11:37:33,699] {taskinstance.py:1703} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1332, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1422, in _execute_task_with_callbacks
    RenderedTaskInstanceFields.write(RenderedTaskInstanceFields(ti=self, render_templates=False))
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/renderedtifields.py", line 126, in write
    session.merge(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2171, in merge
    _resolve_conflict_map=_resolve_conflict_map,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2244, in _merge
    merged = self.query(mapper.class_).get(key[1])
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 1018, in get
    return self._get_impl(ident, loading.load_on_pk_identity)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 1135, in _get_impl
    return db_load_fn(self, primary_key_identity)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/loading.py", line 286, in load_on_pk_identity
    return q.one()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3490, in one
    ret = self.one_or_none()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3459, in one_or_none
    ret = list(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3557, in _execute_and_instances
    querycontext, self._connection_from_session, close_with_result=True
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3572, in _get_bind_args
    mapper=self._bind_mapper(), clause=querycontext.statement, **kw
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 3550, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1145, in connection
    execution_options=execution_options,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1151, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 433, in _connection_for_bind
    conn = bind._contextual_connect()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 241, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1413, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2021-12-29 11:38:20,750] {taskinstance.py:1280} INFO - Marking task as UP_FOR_RETRY. dag_id=scraping_daft_kerry, task_id=run_init_county, execution_date=20211228T094000, start_date=20211229T095605, end_date=20211229T113804
[2021-12-29 10:03:19,942] {process_utils.py:113} WARNING - process psutil.Process(pid=24224, name='airflow task ru', status='running', started='09:56:30') did not respond to SIGTERM. Trying SIGKILL
[2021-12-29 11:39:53,275] {process_utils.py:124} ERROR - Process psutil.Process(pid=24224, name='airflow task ru', status='zombie', started='09:56:30') (24224) could not be killed. Giving up.
[2021-12-29 11:39:58,469] {standard_task_runner.py:135} ERROR - Job 5307 was killed before it finished (likely due to running out of memory)
